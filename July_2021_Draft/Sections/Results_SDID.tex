\documentclass[../Main.tex]{subfiles}

\begin{document}

Nursing home CON laws impose bureaucratic costs to nursing home providers by requiring those planning on opening a new nursing home, expanding a current facility, or offering new beds to first show to a regulatory body that their region needs the service. Propositions \ref{prop3}, \ref{prop2}, and \ref{prop1} predict that repealing nursing home CON will lead to an increase in nursing home quality, an increase in the quantity of nursing home services, and an increase in Medicaid nursing home expenditures, respectively. Based on the results of the model, therefore, we expect the repeal of nursing home CON in PA, IN, and ND to result in an increase in Medicaid nursing home expenditure per capita, as well as an increased quantity of nursing home beds, nursing homes, and specialized care beds (our measures of access to and quality of nursing home services) in all three states. Our empirical findings, the details of which are found in the next two subsections, are consistent with these predictions of our model in all instances of statistical significance, and where pre-treatment trends are reliably parallel.\\
\indent We summarize our main results in tables \ref{tab:ave_results_med_exp_nobord_nocov} through \ref{tab:ave_results_q_specbeds_nobord_nocov} and in figures \ref{fig:med_exp_plots_pa} through \ref{fig:q_certbeds_plots_in}. Tables \ref{tab:ave_results_med_exp_nobord_nocov} through \ref{tab:ave_results_q_specbeds_nobord_nocov} report the average estimated effect, $\hat{\tau}$ from equation (\ref{eq:ave_effect_deltas}), of dropping nursing home CON regulations on each outcome variable of interest in PA (Panel A), IN (Panel B), and ND (Panel C) using the DID (column one), SC (column two), and SDID (column three) estimators. Also reported are standard errors and 95\% confidence intervals using the placebo variance estimation approach outlined in Section \ref{sdid_inference}.\\
\indent Figures \ref{fig:med_exp_plots_pa} through \ref{fig:q_certbeds_plots_in} show a series of plots for each outcome variable and treated state that provide insights into these average effects, parallel pre-trends, and our placebo variance estimation approach to conducting inference outlined in Section \ref{sdid_inference}. More specifically, the top row of plots in each figure show trends in the outcome variable over time for the treated state and for the corresponding weighted average of controls states, with the time weights ($\hat{\lambda}$) used to average pre-treatment time periods at the bottom of the plots. The curved arrows in each of the plots represent the estimated average treatment effect that is reported in Table \ref{tab:ave_results_q_nh}.\footnote{Recall that the SDID estimator re-weights the untreated control states with the goal of making their time trends as parallel as possible, but not necessarily identical, to the treated state in the pre-treatment period, and then applies a DID analysis to this re-weighted panel. Moreover, because of the time weights, the SDID estimator only focuses on a subset of the pre-treatment time periods when carrying out this last step. These time periods are selected so that the weighted average of historical outcomes predict average treatment period outcomes for control states, up to a constant.} The middle row of plots are what we will call ``spaghetti plots,'' which show the year-specific difference in the outcome variable between the treated state and its corresponding weighted average of control states for each of our estimators. The thick blue line shows these gaps for the actual treated state, and the thin pink lines show these gaps for each of the placebo control states used in the placebo variance estimation procedure outlined in Algorithm \ref{alg:two}. To facilitate a more meaningful comparison in how these gaps evolve over time, as well as a good way to visually assess pre-treatment parallel trends, we make the gaps in the DID and SDID plots relative to their value in the year prior to the treated state dropping NH-CON. We do not do this for the SC plot because the SC weights are chosen to match the treated state's actual levels, as opposed to making the trends just parallel (see Section \ref{did_sc_comp}). Not normalizing the gaps for the SC plot allows for a better assessment of the pre-treatment match between the actual treated state, or the placebo ``treated'' state, and its respective synthetic control. The bottom row of plots show the distribution of placebo estimates ($\hat{\tau}^{(b)}$ from Algorithm \ref{alg:two}), with the mean of the placebo estimates and the estimated effect for the actual treated state indicated by the gray and blue vertical lines, respectively.

\subsection{Medicaid and Total Nursing Home Expenditure}

The magnet hypothesis developed in Proposition \ref{prop2} implies that the repeal of nursing home CON in a given state will make the state a type of magnet for nursing home consumers from other states, and perhaps for consumers who would otherwise leave the state. Because a large majority of nursing home consumers are covered by government programs (primarily Medicaid) where prices are relatively inflexible, this predicted increase in the quantity of nursing home services would be expected to result in an increase in Medicaid and total expenditures on nursing home services (Proposition \ref{prop3}). Tables \ref{tab:ave_results_med_exp_nobord_nocov} and \ref{tab:ave_results_tot_exp_nobord_nocov} report the average estimated effect, of dropping nursing home CON regulations on per capita Medicaid and total nursing home expenditure, respectively. Our preferred SDID estimates suggest that, in PA, dropping NH-CON caused an increase of about \$116 in total per capita nursing home expenditure, a 32 percent increase relative to the pre-intervention mean per capita expenditure of \$361.02. The point estimates in Panel A of Table \ref{tab:ave_results_med_exp_nobord_nocov} suggest that the increase in total per capita expenditure is being driven almost entirely by an increase in Medicaid spending. According to our SDID estimates, dropping nursing home CON caused per capita Medicaid expenditure to increase by \$101.73 and \$48.76 in PA and IN, respectively. When compared to their respective pre-intervention average values, these estimated effects are quite large, representing increases in per capita nursing home Medicaid spending of about 70\% in PA and 38\% in IN.\\
\indent Figures \ref{fig:med_exp_plots_pa} -- \ref{fig: tot_exp_spag_plots_nd} show for each treated state, the above-described trend plots, spaghetti plots, and placebo distribution plots for      the quantity of nursing homes per 100,000 outcome. One consequential takeaway from these figures, which is generally true for all outcomes we consider, is that the unit weights used in SC and SDID estimation significantly improve pre-treatment similarities in the levels and trends of the treated states and their synthetic controls. Notice, for example, that for each state in Table \ref{tab:ave_results_q_nh}, the DID estimate is relatively larger than the SC and SDID estimates, particularly for IN. Figures \ref{fig:q_nh_plots_pa} -- \ref{fig: q_nh_spag_plots_nd} illustrate that this is likely a result of non-parallel trends between the treated states (especially Indiana -- Figures \ref{fig:q_nh_plots_in} and \ref{fig: q_nh_spag_plots_in}) and their DID control group.\\
\indent Table \ref{tab:ave_results_tot_exp_nobord_nocov} reports the average estimated effect of dropping NH-CON on total per capita nursing home expenditure. Our SDID estimate suggests that, in PA, dropping NH-CON caused an increase of about \$102 in total per capita nursing home expenditure, a 28.2 percent increase relative to the pre-intervention mean of \$361.02. Here again we see that the parallel trends assumption likely does not hold for our DID estimate (see the non-parallel pre-trends in the DID plots in Figures \ref{fig:tot_exp_plots_pa} and \ref{fig: tot_exp_spag_plots_pa}), resulting in a biased-upward estimate. The pre-treatment trends for the SC and SDID support the parallel trends assumption in PA and the results are statistically significant. We find no evidence that total expenditure was affected by dropping NH-CON in IN. While the point estimates for ND are all positive, its SDID estimate is not significant.\\
\indent  Figures \ref{fig:med_exp_plots_pa} and \ref{fig: med_exp_spag_plots_pa} instill confidence based on pre-trends, that the control groups represent a good counterfactual trajectory for PA. Figure \ref{fig: med_exp_spag_plots_pa} also shows that the estimated effect on Medicaid expenditure in PA is larger than every one of the SDID placebo estimates, and all but one SC placebo estimate. Our SDID estimates in Panel B of Table \ref{tab:ave_results_med_exp} suggest that, in IN, NH-CON lead to an increase of \$49.58 per capita in Medicaid expenditures, which represents an increase of 38.7 percent relative to the pre-period mean of \$129.12 per capita. the pre-treatment trends for IN shown in figures \ref{fig:med_exp_plots_pa} show strong evidence for the parallel trends assumption in the SDID results, and the the point estimate from the SDID analysis is marginally significant. Figures \ref{fig:med_exp_plots_in} and \ref{fig: med_exp_spag_plots_in} show that the effect on Medicaid in IN is larger than all but 3 placebo states. Our estimates in Panel C of Table \ref{tab:ave_results_med_exp} are all negative, suggesting that dropping NH-CON in ND may have actually decreased Medicaid expenditure. However, an inspection of Figures \ref{fig:med_exp_plots_nd} and \ref{fig:med_exp_plots_nd} reveal that these point estimates are unreliable given the obvious lack of pre-treatment parallel trends. In other words, given the spike and subsequent fall in Medicaid expenditure per capita in ND, the control groups, even with optimal SDID weights, fail to provide a reasonable counterfactual trajectory for ND.

\subsection{Quantity of Nursing Homes and Nursing Home Beds}

\indent Table \ref{tab:ave_results_q_nh} reports the average estimated effect of dropping NH-CON regulations on the quantity of nursing homes per 100,000. According to our preferred SDID estimates, which in this case are very similar to the SC estimates, dropping NH-CON caused an increase of 0.43, 0.20, and 0.30 nursing homes per 100,000 in PA, IN, and ND, respectively. Also reported are the standard errors and 95\% confidence intervals derived using the placebo variance estimation approach outlined in Section \ref{sdid_inference}, which suggest that the SDID estimate for PA is statistically significant and the estimate for IN is marginally insignificant. These estimated effects are quite large when compared to the average quantity of nursing homes per 100,000 over the pre-intervention period. For example, an increase of 0.43 nursing homes per 100,000 in PA is an increase of 68.3 percent relative to its pre-intervention average of 0.63. Thus, these results show that the effect of nursing home CON on the quantity of nursing homes is not only consistent with our model, but also substantial and economically meaningful, especially in PA.  \\
\indent We will be showing similar graphs to Figures \ref{fig:q_nh_plots_pa} and \ref{fig: q_nh_spag_plots_pa} for each outcome variable and each treated state, so it will be helpful to describe in detail what each of these figures contain. The top panel of Figure \ref{fig:q_nh_plots_pa} shows trends in the quantity of nursing homes per 100,000 over time for PA and for the corresponding weighted average of controls states, with the time weights ($\hat{\lambda}$) used to average pre-treatment time periods at the bottom of the plots. The curved arrows in each of the plots represent the estimated average treatment effect that is reported in Table \ref{tab:ave_results_q_nh}. Recall that the SDID estimator re-weights the untreated control states with the goal of making their time trends as parallel as possible, but not necessarily identical, to the treated state in the pre-treatment period, and then applies a DID analysis to this re-weighted panel. Moreover, because of the time weights, the SDID estimator only focuses on a subset of the pre-treatment time periods when carrying out this last step. These time periods are selected so that the weighted average of historical outcomes predict average treatment period outcomes for control states, up to a constant. The bottom panel of Figure \ref{fig:q_nh_plots_pa} shows the state-by-state adjusted outcome differences $\hat{\delta}_{tr}-\hat{\delta}_i$ as specified in equations (\ref{eq:sc_deltas}), (\ref{eq:did_deltas}), and (\ref{eq:sdid_deltas}), with weights $\hat{\omega}_i$ indicated by dot size, and the weighted average of these differences - the same estimated effect $\hat{\tau}$ - indicated by the horizontal lines.\\
\indent Figure \ref{fig: q_nh_spag_plots_pa} provides some insights into our placebo variance estimation approach to conducting inference outlined in Section \ref{sdid_inference}. Specifically, the top panel of Figure \ref{fig: q_nh_spag_plots_pa} shows with what we will call ``spaghetti plots,'' the year-specific difference in the quantity of nursing homes per 100,000 between the treated state and its corresponding weighted average of control states for each of our estimators. The thick blue line shows these gaps for the actual treated state (PA in this case), and the thin pink lines show these gaps for each of the placebo control states used in the placebo variance estimation procedure outlined in Algorithm \ref{alg:two}. To facilitate a more meaningful comparison in how these gaps evolve over time, as well as a good way to visually assess pre-treatment parallel trends, we make the gaps in the DID and SDID plots relative to their value in the year prior to the treated state dropping NH-CON. We do not do this for the SC plot because the SC weights are chosen to match the treated state's actual levels, as opposed to making the trends just parallel (see Section \ref{did_sc_comp}). Not normalizing the gaps for the SC plot allows for a better assessment of the pre-treatment match between the actual treated state, or the placebo ``treated'' state, and its respective synthetic control. The plots in the bottom panel of Figure \ref{fig: q_nh_spag_plots_pa} show the distribution of placebo estimates ($\hat{\tau}^{(b)}$ from Algorithm \ref{alg:two}), with the mean of the placebo estimates and the estimated effect for the actual treated state (PA in this case) indicated by the gray and blue vertical lines, respectively.\\  
\indent Figures \ref{fig:q_nh_plots_pa} -- \ref{fig: q_nh_spag_plots_nd} show for each treated state, these trend plots, state-by-state outcome differences $\hat{\delta}_{tr}-\hat{\delta}_i$, spaghetti plots, and placebo distribution plots for the quantity of nursing homes per 100,000 outcome. One consequential takeaway from these figures, which is generally true for all outcomes we consider, is that the unit weights used in SC and SDID estimation significantly improve pre-treatment similarities in the levels and trends of the treated states and their synthetic controls. Notice, for example, that for each state in Table \ref{tab:ave_results_q_nh}, the DID estimate is relatively larger than the SC and SDID estimates, particularly for IN. Figures \ref{fig:q_nh_plots_pa} -- \ref{fig: q_nh_spag_plots_nd} illustrate that this is likely a result of non-parallel trends between the treated states (especially Indiana -- Figures \ref{fig:q_nh_plots_in} and \ref{fig: q_nh_spag_plots_in}) and their DID control group.\\
\indent A similar story emerges when we consider an alternative measure of the quantity of nursing home services -- the quantity of nursing home beds per 100,000. Table \ref{tab:ave_results_q_nhb} reports the average estimated effect of dropping NH-CON regulations on this outcome for each of our three treated states and estimators. Figures \ref{fig:q_nhb_plots_pa} -- \ref{fig: q_nhb_spag_plots_nd} show analogous trend plots, state-by-state outcome differences and weights, spaghetti plots, and placebo distribution plots for this alternative measure of the quantity of nursing home services. The point estimates in Table \ref{tab:ave_results_q_nhb} are all positive and there is strong evidence for the parallel trends assumption given their pre-treatment trends, indicating that dropping NH-CON resulted in more nursing home beds available in the treated states. However, only the point estimates for Indiana are statistically significant. The spaghetti and placebo distribution plots in Figures \ref{fig: q_nhb_spag_plots_pa}, \ref{fig: q_nhb_spag_plots_in}, and \ref{fig: q_nhb_spag_plots_nd} illustrate that there is considerable noise in the placebo estimates, being in part driven by several extremely large placebo estimates.\\
\indent \citet{abadie2010synthetic} discuss removing placebo units that, in the context of SC estimation, do not have a reasonably good fit in terms of pre-period mean-squared prediction error compared to that of the treated unit. This same idea can be applied to the SDID estimation. When considering nursing home expenditure outcomes in the next section, we follow \citet{abadie2010synthetic} in dropping Washington DC from the analysis because we could not find anything remotely close to a good control group (in terms of pre-treatment levels and parallel trends). While it is clear that some placebo states had non-parallel pre-trends and a poor fit in both SC and SDID analyses of the quantity of nursing home beds, we chose to include them to be conservative and transparent, despite the resultant larger estimated variance and standard errors.



\end{document}